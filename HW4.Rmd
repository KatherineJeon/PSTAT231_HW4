---
title: "HW4"
output: html_document
date: '2022-04-27'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(visdat)
library(corrplot)
library(discrim)
library(klaR)
library(yardstick)
```

```{r}
set.seed(45)
titanic = read.csv('data/titanic.csv')
titanic$survived = factor(titanic$survived, levels = c('Yes', 'No'))
titanic$pclass = factor(titanic$pclass)
```


## Question 1

```{r}
titanic_split <- initial_split(titanic, prop = 0.8,
                                strata = survived)
titanic_train <- training(titanic_split)
titanic_test <- testing(titanic_split)
```


## Question 2

```{r}
cv_folds <- vfold_cv(titanic_train, v = 10)
```


## Question 3

k-cross validation shuffles the dataset randomly and split the data into k groups. When splited, the model that we designed is trained with k-1 of the folds of training data and the resulting model is validated on the remaining data. By using k-cross-validation, we don'tneed to spare extra data for  validation set. If we didn't used cross-validation here, the sampling method would have been stratified random sampling. 


## Question 4

```{r}
titanic_recipe = recipe(survived ~ pclass + sex + age + sib_sp + parch + fare, 
                        data = titanic_train) %>%
        step_impute_linear(age) %>%
        step_dummy(all_nominal_predictors()) %>%
        step_interact(terms = ~ starts_with("sex"):fare + age:fare)


log_reg = logistic_reg() %>% 
        set_engine("glm") %>% 
        set_mode("classification")

log_wkflow = workflow() %>% 
        add_model(log_reg) %>% 
        add_recipe(titanic_recipe)

log_fit = fit(log_wkflow, titanic_train)


lda_mod = discrim_linear() %>%
        set_engine("MASS") %>%
        set_mode("classification")

lda_wkflow = workflow() %>% 
        add_model(lda_mod) %>% 
        add_recipe(titanic_recipe)

lda_fit = fit(lda_wkflow, titanic_train)


qda_mod = discrim_quad() %>% 
        set_mode("classification") %>% 
        set_engine("MASS")

qda_wkflow = workflow() %>% 
        add_model(qda_mod) %>% 
        add_recipe(titanic_recipe)

qda_fit = fit(qda_wkflow, titanic_train)
```
we are fitting 3 models with 10 folds each, so 3 * 10 = 30 folds


## Question 5

```{r}
log_res = log_wkflow %>% 
        fit_resamples(resamples = cv_folds, 
                      metrics = metric_set(recall, precision, 
                                           accuracy, sens, spec, roc_auc),
                      control = control_resamples(save_pred = TRUE)) 

lda_res = lda_wkflow %>%
        fit_resamples(resamples = cv_folds,
                      metrics = metric_set(recall, precision, 
                                           accuracy, sens, spec, roc_auc),
                      control = control_resamples(save_pred = TRUE))

qda_res = qda_wkflow %>%
        fit_resamples(resamples = cv_folds,
                      metrics = metric_set(recall, precision, 
                                           accuracy, sens, spec, roc_auc),
                      control = control_resamples(save_pred = TRUE))
```


## Question 6

```{r}
collect_metrics(log_res)
collect_metrics(lda_res)
collect_metrics(qda_res)
```
Logistic regression had the highest accuracy


## Question 7

```{r}
log_fit <- fit(log_wkflow, titanic_train)
```


## Question 8

```{r}
log_test <- predict(log_fit, new_data = titanic_test, type = 'prob')
log_test <- bind_cols(log_test, titanic_test)
log_acc = augment(log_fit, new_data = titanic_test) %>%
  accuracy(truth = survived, estimate = .pred_class)

log_acc
```


## Question 9
$$
\hat{\beta} = \bar{Y}
$$



## Question 10



